{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import math\n",
    "import random\n",
    "from itertools import combinations \n",
    "import timeit\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCv Version: 3.4.2\n"
     ]
    }
   ],
   "source": [
    "print('OpenCv Version:',cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(image):\n",
    "    cv2.imshow(\"img\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(path, img):\n",
    "    cv2.imwrite(path,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "transA = cv2.imread(\"data/simA.jpg\", 0)\n",
    "transB = cv2.imread(\"data/simB.jpg\", 0)\n",
    "simA = cv2.imread(\"data/simA.jpg\", 0)\n",
    "simB = cv2.imread(\"data/simB.jpg\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "transA = cv2.resize(transA, dsize=(400,800))\n",
    "transB = cv2.resize(transB, dsize=(400,800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(transB)\n",
    "transA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients_all(img):\n",
    "    ret = {}\n",
    "    \n",
    "    img_g = cv2.GaussianBlur(img, (5,5), sigmaX = 2)\n",
    "    \n",
    "    Ix = cv2.Sobel(img_g, cv2.CV_64F, 1, 0, ksize = 5) #kernel_sum = 240\n",
    "    Iy = cv2.Sobel(img_g, cv2.CV_64F, 0, 1, ksize = 5)\n",
    "    \n",
    "    com_img = np.hstack((Ix,Iy))\n",
    "#     imshow(com_img, cmap='gray');\n",
    "    \n",
    "    Ixx = Ix * Ix\n",
    "    Ixy = Ix * Iy\n",
    "    Iyy = Iy * Iy\n",
    "    \n",
    "    parameters = {\n",
    "        \"img\": img_g,\n",
    "        \"Ix\" : Ix,\n",
    "        \"Iy\" : Iy,\n",
    "        \"Ixx\": Ixx,\n",
    "        \"Ixy\": Ixy,\n",
    "        \"Iyy\": Iyy,\n",
    "          }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(res, offset = 1):\n",
    "    \n",
    "    h, w = res.shape\n",
    "    \n",
    "    for i in range(offset, h - offset):\n",
    "        for j in range(offset, w - offset):\n",
    "            b = res[i - offset: i + offset + 1, j - offset: j + offset + 1]\n",
    "            m = b.max()\n",
    "            b[b<m] = 0\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harris_response(parameters, k = 0.05, offset = 1):\n",
    "    \n",
    "    img = parameters[\"img\"]\n",
    "    Ix = parameters[\"Ix\"]\n",
    "    Iy = parameters[\"Iy\"]\n",
    "    Ixx = parameters[\"Ixx\"]\n",
    "    Ixy = parameters[\"Ixy\"]\n",
    "    Iyy = parameters[\"Iyy\"]\n",
    "    \n",
    "#     detA = Ixx + Iyy - 2 * Ixy\n",
    "    \n",
    "#     traceA = Ixx + Iyy\n",
    "    \n",
    "#     response = detA - k * (traceA ** 2)\n",
    "    \n",
    "    h,w = parameters[\"img\"].shape\n",
    "    Sxx = np.zeros((h, w)) #(h - 2 * offset,w - 2 * offset)\n",
    "    Sxy = np.zeros((h, w))\n",
    "    Syy = np.zeros((h, w))\n",
    "    \n",
    "    for i in range(offset, h - offset):\n",
    "        for j in range(offset, w - offset):\n",
    "            Sxx[i, j] = np.sum(Ixx[i - offset: i + offset + 1, j - offset: j + offset + 1])\n",
    "            Sxy[i, j] = np.sum(Ixy[i - offset: i + offset + 1, j - offset: j + offset + 1])\n",
    "            Syy[i, j] = np.sum(Iyy[i - offset: i + offset + 1, j - offset: j + offset + 1])\n",
    "    \n",
    "#     mat = [\n",
    "#              [Sxx, Sxy]\n",
    "#              [Sxy, Syy]\n",
    "#           ]\n",
    "    \n",
    "    \n",
    "    det = Sxx * Syy - Sxy ** 2\n",
    "    trace = Sxx + Syy\n",
    "    \n",
    "    res = det - k * (trace ** 2)\n",
    "    img_corners = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    corners = []\n",
    "    \n",
    "    #thresholding\n",
    "    max_response = res.max()\n",
    "    res[res < max_response * 0.01] = 0\n",
    "    \n",
    "    #non-max-suppression\n",
    "    res = non_max_suppression(res, offset=2)\n",
    "    \n",
    "    \n",
    "    for i in range(offset,h-offset):\n",
    "        for j in range(offset,w-offset):\n",
    "            if res[i, j] > 0: # response > 0 === corner\n",
    "                img_corners[i, j] = [0, 255, 0]\n",
    "#                 points.append([i,j])\n",
    "#                 kp = cv2.KeyPoint(j,i, _size = 1, _angle=np.degrees(math.atan2(Iy[i, j+1] - Iy[i,j-1],Ix[i+1, j] - Ix[i-1,j])))\n",
    "                kp = cv2.KeyPoint(j,i, _size = 2, _angle=np.degrees(math.atan(-Iy[i, j] / Ix[i, j])))\n",
    "#                 kp = cv2.KeyPoint(j,i, _size = 1, _angle=np.degrees(np.arctan2(Iy[i, j],Ix[i, j]))+180)\n",
    "                corners.append(kp)  \n",
    "    \n",
    "    #storing data\n",
    "    parameters[\"img_corners\"] = img_corners\n",
    "    parameters[\"corners\"] = corners\n",
    "    parameters[\"response\"] = res\n",
    "    \n",
    "    return parameters\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift(parameters):\n",
    "    \n",
    "    img = parameters[\"img\"]\n",
    "    corners = parameters[\"corners\"]\n",
    "    \n",
    "    #SIFT\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "    \n",
    "    parameters[\"keypoints\"] = keypoints\n",
    "    parameters[\"descriptors\"] = descriptors\n",
    "    \n",
    "    img_key = cv2.drawKeypoints(parameters[\"img\"],parameters[\"keypoints\"],img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "#     display(img_key)\n",
    "    \n",
    "    return parameters\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(p1, p2):\n",
    "    \n",
    "    des1 = p1[\"descriptors\"]\n",
    "    des2 = p2[\"descriptors\"]\n",
    "    \n",
    "    matcher = cv2.BFMatcher()\n",
    "    matches = matcher.match(des1, des2)\n",
    "    \n",
    "    matches = sorted(matches, key = lambda m : m.distance)\n",
    "    \n",
    "    return matches    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(img):\n",
    "    \n",
    "    # p - parameters\n",
    "    p = gradients_all(img)\n",
    "    p = harris_response(p)\n",
    "    p = sift(p)\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(parameters[\"img_corners\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tic = timeit.default_timer()\n",
    "resA = compute(transA)\n",
    "resB = compute(transB)\n",
    "# toc = timeit.default_timer()\n",
    "# print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = match(resA, resB)\n",
    "matches = sorted(matches, key = lambda x : x.distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = cv2.drawMatches(transA, resA[\"keypoints\"], transB, resB[\"keypoints\"], matches[:10], outImg = transA, flags=2)\n",
    "display(img3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ransac(matches,k2,k1, pick = 5, threshold = 2):\n",
    "    \n",
    "    ind_hits = np.array([])\n",
    "    con_set  = []\n",
    "    \n",
    "    for i in range(pick):\n",
    "        \n",
    "        ind = random.choice(range(0,20))\n",
    "\n",
    "        train_point = k1[matches[ind].trainIdx]\n",
    "        query_point = k2[matches[ind].queryIdx]\n",
    "\n",
    "        x_trans = abs(train_point.pt[0] - query_point.pt[0])\n",
    "        y_trans = abs(train_point.pt[1] - query_point.pt[1])\n",
    "\n",
    "        p = 0\n",
    "        k = 0\n",
    "        matched_indices = []\n",
    "        \n",
    "        for j in matches:\n",
    "            \n",
    "#             print(\"> looking \",x_trans,y_trans)\n",
    "            p += 1\n",
    "    \n",
    "            train_point = k1[j.trainIdx]\n",
    "            query_point = k2[j.queryIdx]\n",
    "            \n",
    "            x_trans_temp = abs(train_point.pt[0] - query_point.pt[0])\n",
    "            y_trans_temp = abs(train_point.pt[1] - query_point.pt[1])\n",
    "            \n",
    "#             print(\"    > looking \", x_trans_temp, y_trans_temp)\n",
    "            \n",
    "            if x_trans_temp <= x_trans + threshold and x_trans_temp >= x_trans - threshold:\n",
    "#                 print(\"first firewall\")\n",
    "                if y_trans_temp <= y_trans + threshold and y_trans_temp >= y_trans - threshold:\n",
    "#                     print(\"second firewall\", k, ind, p)\n",
    "                    k += 1\n",
    "                    matched_indices.append(j)\n",
    "        \n",
    "        print(k)\n",
    "#         print(matched_indices)\n",
    "            \n",
    "        ind_hits = np.append(ind_hits, k)\n",
    "        con_set.append(matched_indices)\n",
    "\n",
    "    return ind_hits, con_set\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp = resA[\"keypoints\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "5\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "\n",
      "Result: 0 5\n"
     ]
    }
   ],
   "source": [
    "ind_hits, con_set = ransac(matches, resA[\"keypoints\"], resB[\"keypoints\"], threshold=1.8, pick=15)\n",
    "m = ind_hits.argmax()\n",
    "print(\"\\nResult:\", m, len(con_set[m]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<DMatch 0x7f98912db0f0>,\n",
       " <DMatch 0x7f98912db130>,\n",
       " <DMatch 0x7f98912db050>,\n",
       " <DMatch 0x7f98912db1b0>,\n",
       " <DMatch 0x7f98912db070>]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_set[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = cv2.drawMatches(transA, resA[\"keypoints\"], transB, resB[\"keypoints\"], con_set[m][:] , outImg = transA, flags=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.array([[0., 0., 0.],\n",
    "              [0., 0., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Found T in: 1 Attempts\n"
     ]
    }
   ],
   "source": [
    "k1 = resA[\"keypoints\"]\n",
    "k2 = resB[\"keypoints\"]\n",
    "f = False\n",
    "print(len(con_set[m])-2)\n",
    "for j in range(len(con_set[m])-2):\n",
    "    points1 = []\n",
    "    points2 = []\n",
    "    for i in range(j,j+3):\n",
    "        d = con_set[m][i]\n",
    "        points1.append([k2[d.trainIdx].pt[0],k2[d.trainIdx].pt[1]])\n",
    "\n",
    "        points2.append([k1[d.queryIdx].pt[0],k1[d.queryIdx].pt[1]])\n",
    "\n",
    "    points1 = np.float32(points1)\n",
    "    points2 = np.float32(points2)\n",
    "    T = cv2.getAffineTransform(points1, points2)\n",
    "    if (T == k).all() != True:\n",
    "        f = True\n",
    "        h, w = resA[\"img\"].shape\n",
    "        img = cv2.warpAffine(resB[\"img\"], T,(w,h))\n",
    "        display(img)\n",
    "        break\n",
    "        \n",
    "    print(\"Failed :\", j + 1)\n",
    "if f:\n",
    "    print(\"Found T in:\", j+1, \"Attempts\")\n",
    "else:\n",
    "    print(\"[+] Tune Hyperparameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.C II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(combinations(range(0,m),3))\n",
    "c = np.array(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k1 = resA[\"keypoints\"]\n",
    "k2 = resB[\"keypoints\"]\n",
    "f = False\n",
    "# print(len(con_set[m])-2)\n",
    "con = matches[0:20] #con_set[m]\n",
    "c = list(combinations(range(0,len(con)),3))\n",
    "c = np.array(c)\n",
    "t_mats = []\n",
    "for j in range(len(c)):\n",
    "    points1 = []\n",
    "    points2 = []\n",
    "    for i in range(0,3):\n",
    "#         print(j,i)\n",
    "        d = con[c[j][i]]\n",
    "        points1.append([k2[d.trainIdx].pt[0],k2[d.trainIdx].pt[1]])\n",
    "\n",
    "        points2.append([k1[d.queryIdx].pt[0],k1[d.queryIdx].pt[1]])\n",
    "\n",
    "    points1 = np.float32(points1)\n",
    "    points2 = np.float32(points2)\n",
    "    T = cv2.getAffineTransform(points1, points2)\n",
    "    if (T == k).all() != True:\n",
    "        f = True\n",
    "        h, w = resA[\"img\"].shape\n",
    "        img = cv2.warpAffine(resB[\"img\"], T,(w,h))\n",
    "        t_mats.append(T)\n",
    "#         display(img)\n",
    "#         break\n",
    "#         print(T)\n",
    "        \n",
    "#         print(\" \")\n",
    "        \n",
    "#     print(\"Failed :\", j + 1)\n",
    "\n",
    "# if f:\n",
    "#     print(\"Found T in:\", j+1, \"Attempts\")\n",
    "# else:\n",
    "#     print(\"[+] Tune Hyperparameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "Min Score: 2534708.6148207067\n",
      "Max Score: 783771136.9923506\n",
      "Time: 7.2288667319953674\n",
      "Position: 859\n"
     ]
    }
   ],
   "source": [
    "#L2_NORM\n",
    "tic = timeit.default_timer()\n",
    "l = len(t_mats)\n",
    "scores = []\n",
    "for i in range(l):\n",
    "    score = 0\n",
    "    for j in range(l):\n",
    "        score += np.sum((t_mats[i] - t_mats[j])**2)\n",
    "    scores.append(score)\n",
    "# print(scores)\n",
    "scores = np.array(scores)\n",
    "p = np.argmin(scores)\n",
    "p_max = np.argmax(scores)\n",
    "toc = timeit.default_timer()\n",
    "# print(p)\n",
    "print(\"Result:\")\n",
    "print(\"Min Score:\", scores.min())\n",
    "print(\"Max Score:\", scores.max())\n",
    "print(\"Time:\", toc-tic)\n",
    "print('Position:', p)\n",
    "\n",
    "final_t = t_mats[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.warpAffine(transB, t_mats[p],(w,h))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('data/min_score_match_20.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.warpAffine(transB, T,(w,h))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(transA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-199-2f3c78a22ec1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcon_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.95430537,   0.20773628, -10.74871998],\n",
       "       [ -0.28323644,   0.96030581,  66.62533016]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_new = compute(img)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_new = match(resA, res_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_new = sorted(matches_new, key = lambda x : x.distance)\n",
    "img3 = cv2.drawMatches(transA, resA[\"keypoints\"], img, res_new[\"keypoints\"], matches_new[:10], outImg = transA, flags=2)\n",
    "display(img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[356.84634 , 237.71532 ],\n",
       "       [110.705986, 193.5702  ],\n",
       "       [347.84515 , 214.80489 ]], dtype=float32)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[296.66254 , 379.27124 ],\n",
       "       [110.313896, 255.22346 ],\n",
       "       [289.99185 , 184.02068 ]], dtype=float32)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.copy(resA[\"img\"])\n",
    "g = np.copy(resB[\"img\"])\n",
    "for i in range(3):\n",
    "    cv2.circle(g,tuple(points1[i]),1,(255,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.351591110229492"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_new[5].distance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv-env-3.4.2.16",
   "language": "python",
   "name": "opencv-env-3.4.2.16"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
